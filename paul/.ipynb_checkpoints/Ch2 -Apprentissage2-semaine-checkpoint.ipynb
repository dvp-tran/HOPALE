{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <a> Apprentissage </a> </h1>\n",
    "<h2> Pour le Challenge Axa </h2>\n",
    "<h3> Axa Graduate Program Février 2017 </h3>\n",
    "<i> Author : Paul Tran </i> <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "1. [Préliminaires](#préliminaires)\n",
    "    1. [Introduction](#introduction)\n",
    "    2. [Imports](#imports)\n",
    "    3. [Chargement de la donnée](#load)\n",
    "2. [Data Management](#management)\n",
    "    1. [Train, Validation & Test](#split)\n",
    "    2. [Description de la donnée](#description)\n",
    "3. [Machine Learning](#ML)\n",
    "    1. [Méthode Linéaire](#linéaire)\n",
    "        1. [Régression Linéaire simple](#RF)\n",
    "        2. [Lasso](#ET)\n",
    "    2. [Méthodes ensemblistes](#ensemblistes)\n",
    "        1. [Random Forest](#RF)\n",
    "        2. [Extra Trees](#ET)\n",
    "        3. [XG Boost](#XGB)\n",
    "4. [Interprétation des modèles](#interprétation)\n",
    "5. [Soumission des résultats](#submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préliminaires  <a name=\"préiliminaires\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Introduction :  <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie nous allons gérer l'approche naïve de l'apprentissage avec très peu de modifications sur la donnée. Nous tenterons par la suite d'effectuer un travail plus réfléchi sur la donnée dans l'optique d'obtenir un meilleur score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Précautions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook prend beaucoup de temps à être exécuté dans son intégralité du fait des apprentissages successifs qui sont lancés. Il est conseiller de ne pas l'exécuter et d'observer directement les résultats des cellules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Imports des librairies utiles <a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 300)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#pour la partie data viz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import bokeh\n",
    "#from bokeh.io import output_notebook\n",
    "#output_notebook()\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chargement de la donnée  <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/synthese.xlsx')\n",
    "aux = pd.read_excel('../data/extrait_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop useless\n",
    "to_drop = [\"annee\",\"GME_ATIH\",\"chapitre\",\"GN\",\"RGME\",\"sortie\",u'Médecin',\"dep_totale\"]\n",
    "target = [\"nb_rhs\"]\n",
    "target_related = [ u'nb_rhs', u'nb_jours_total', u'nb_jours_WE']\n",
    "rename_mapper = {\"date_2\":\"date_entree\",\n",
    "                 \"jour\":\"jour_entree\",\n",
    "                 \"mois\":\"mois_entree\",\n",
    "                 \"annee\":\"annee_entree\"}\n",
    "df = df.drop(to_drop,axis=1)\n",
    "aux= aux.drop([\"date\"], axis = 1).rename(rename_mapper, axis=1)\n",
    "\n",
    "#cast date type such as date\n",
    "aux[\"date_entree\"]= pd.to_datetime(aux[\"date_entree\"])\n",
    "\n",
    "#left join on N_ordre\n",
    "data = pd.merge(df,aux,on=\"N_ordre\",how=\"left\")\n",
    "\n",
    "#fill na to 0 for the \n",
    "practiciens = [u'Animateur', u'Assistant de service social',\n",
    "                 u'Autre intervenant',                 u'Diététicien',\n",
    "              u'Éducateur spécialisé',           u'Éducateur sportif',\n",
    "                u'Enseignant général',                    u'Ergonome',\n",
    "                    u'Ergothérapeute',                   u'Infirmier',\n",
    "           u'Masseurkinésithérapeute',        u'Moniteur d’autoécole',\n",
    "                u'Moniteur éducateur',               u'Orthophoniste',\n",
    "                  u'Orthoprothésiste',                  u'Osteopathe',\n",
    "                       u'Psychologue',             u'Psychomotricien']\n",
    "\n",
    "for col in practiciens:\n",
    "    data[col] = data[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous n'observons que le début de la table pour s'assurer qu'elle s'est bien chargée.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data Engineering  <a name=\"management\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = [\"nb_rhs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Features\n",
    "\n",
    "#create age instead at time of entry\n",
    "data[\"Age\"] = data[\"annee_entree\"] - data[\"annee_naissance\"]\n",
    "\n",
    "#create indicator for u'nb_jours_WE'\n",
    "def weekend_indicator(x):\n",
    "    \"\"\"input : x scalar\"\"\"\n",
    "    if x < 0.8:\n",
    "        return 0\n",
    "    if x>=0.8 and x<1.8:\n",
    "        return 1\n",
    "    if x>=1.8:\n",
    "        return 2\n",
    "data[\"weekend_indicator\"] = (data[\"nb_jours_WE\"]/data[\"nb_rhs\"]).apply(lambda x :weekend_indicator(x))\n",
    "\n",
    "#add nombre d'intervenants\n",
    "def nb_inter(row,practiciens):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    row : row of dataframe\n",
    "    practiciens : métier\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for col in practiciens:\n",
    "        if row[col]>0:\n",
    "            count+=1\n",
    "    return count\n",
    "data[\"Nb_intervenants\"] = data.apply(lambda row : nb_inter(row,practiciens),axis=1)\n",
    "\n",
    "data['Total_interventions'] = data[practiciens].sum(axis=1)\n",
    "\n",
    "#eliminate those who have Nb_intervenants = 0\n",
    "data = data[data[\"Nb_intervenants\"]>0].reset_index(drop = True)\n",
    "data = data[data[\"nb_rhs\"]<39].reset_index(drop = True)\n",
    "#data = data[data[target]>0].reset_index(drop = True)\n",
    "\n",
    "#regroup by postal county\n",
    "#CP est un type entier reformater en string avec 0 devant\n",
    "data['CP'] = data['CP'].apply(lambda x : str(x).zfill(5))\n",
    "data['CP_departement']=data['CP'].apply(lambda x : x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#threshold and discretize \n",
    "\n",
    "#Creation de la variable “chapitre” simplifiee : \n",
    "#Correlation la plus grande avec “NbSemaines”\n",
    "def simple_chap(chapitre):\n",
    "    if \"08\" in chapitre:\n",
    "        return 0\n",
    "    if \"01\" in chapitre:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "data[\"T_chapitre_discretized\"] = data[\"T_chapitre\"].apply(lambda x : simple_chap(x))\n",
    "\n",
    "\n",
    "thresh_practiciens = {\n",
    "     u'Animateur' : 909,\n",
    "     u'Assistant de service social':243,\n",
    "     u'Autre intervenant':227,\n",
    "     u'Di\\xe9t\\xe9ticien':81,\n",
    "     u'\\xc9ducateur sp\\xe9cialis\\xe9':913,\n",
    "     u'\\xc9ducateur sportif':781,\n",
    "     u'Enseignant g\\xe9n\\xe9ral':1888,\n",
    "     u'Ergonome':258,\n",
    "     u'Ergoth\\xe9rapeute':781,\n",
    "     u'Infirmier':411,\n",
    "     u'Masseurkin\\xe9sith\\xe9rapeute':1419,\n",
    "     u'Moniteur d\\u2019auto\\xe9cole':338,\n",
    "     u'Moniteur \\xe9ducateur':1715,\n",
    "     u'Orthophoniste':945,\n",
    "     u'Orthoproth\\xe9siste':84,\n",
    "     u'Osteopathe':194,\n",
    "     u'Psychologue':364,\n",
    "     u'Psychomotricien':577\n",
    "}\n",
    "\n",
    "#Discretise for each practicien:\n",
    "for col in practiciens:\n",
    "    thresh = thresh_practiciens[col]\n",
    "    data[u\"%s_discretized\"%col]  = data[col].apply(lambda x : 1 if x>0 and x<=thresh else (2 if x>thresh else 0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_meanbycategory(column_name):\n",
    "    mean_by_category = newdata[[column_name, 'Total duration']].groupby([column_name], as_index=False).mean()\n",
    "    category_list = np.asarray(mean_by_category[column_name]).tolist()\n",
    "    mean_list = np.asarray(mean_by_category['Total duration']).tolist()\n",
    "    return category_list, mean_list\n",
    "\n",
    "feature = 'BaseInpatientInformation#Diagnostic code'\n",
    "newfeature = 'BaseInpatientInformation#Diagnostic code#Mean'\n",
    "\n",
    "categories, means = get_meanbycategory(feature)\n",
    "\n",
    "def apply_meancategory(x):\n",
    "    index = categories.index(x)\n",
    "    return means[index]\n",
    "\n",
    "newdata[newfeature] = newdata[feature].apply(apply_meancategory)\n",
    "\n",
    "agg_funcs = {'Total duration': ['count']}\n",
    "newdata[[newfeature,'Total duration']] \\\n",
    "    .groupby([newfeature], as_index=False) \\\n",
    "    .agg(agg_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mean et mediane\n",
    "GN_Avg_Med = pd.read_csv(\"../data/aux/GN_Avg_Med.csv\",sep=\",\",encoding=\"utf8\")\n",
    "data = pd.merge(data,GN_Avg_Med,on=\"T_GN\",how=\"left\")\n",
    "left_cols = [x+\"_x\" for x in GN_Avg_Med.columns if x != \"T_GN\"]\n",
    "\n",
    "Chapitre_Avg_Med = pd.read_csv(\"../data/aux/Chapitre_Avg_Med.csv\",sep=\",\",encoding=\"utf8\").rename({\"T_Chapitre\":\n",
    "                                                                                                  \"T_chapitre\"},axis=1)\n",
    "data = pd.merge(data,Chapitre_Avg_Med,on=\"T_chapitre\",how=\"left\")\n",
    "left_cols = left_cols + [x+\"_y\" for x in Chapitre_Avg_Med.columns if x != \"T_chapitre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    #summary\n",
    "    summary =  pd.DataFrame()\n",
    "    cols = list(df.columns)\n",
    "    summary[\"column\"] =  cols\n",
    "    summary[\"type\"] = list(df[cols].dtypes)\n",
    "    summary[\"nb_missing_values\"] = list(df[cols].isnull().sum())\n",
    "    summary[\"nb_missing_values%\"] = summary[\"nb_missing_values\"]/len(df)*100\n",
    "    summary[\"nb_unique\"]= [df[x].dropna().nunique() for x in summary[\"column\"]]\n",
    "    summary.set_index(\"column\",inplace=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useless = []+practiciens\n",
    "option =[\"dep_sup\",\"dep_physique\",\"CP\",\"jour_entree\",\"mois_entree\",\n",
    "        \"annee_entree\",\"weekend_indicator\",\"T_GN\"]\n",
    "keep = [\"N_ordre\",\"type hosp\",\n",
    "        \"T_chapitre_discretized\",\"sexe\",\"Age\",\"weekend_indicator\",\n",
    "        \"entree\",\"Nb_intervenants\",\"dep_sup\",\"dep_physique\"]+left_cols+target\n",
    "\n",
    "keep_ = []\n",
    "for col in practiciens:\n",
    "    keep_.append(u\"%s_discretized\"%col)\n",
    "    \n",
    "data = data[keep+keep_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_categorical = [\"T_chapitre_discretized\",\"sexe\",\"entree\"]\n",
    "data = pd.get_dummies(data, columns=list_categorical,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_dummies = [x for x in data.columns if any(y in x for y in list_categorical) ]\n",
    "keep = [x for x in keep if x not in list_categorical + target+[\"N_ordre\"]]+cols_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Train, Validation & Test set  <a name=\"split\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***La donnée étant déjà traité de façon la plus simple depuis le premier Notebook, nous nous contentons pour notre première approche \"naïve\" de simplement séparer notre base de train afin de pouvoir évaluer le modèle d'apprentissage.***\n",
    "\n",
    "***Nous la considérons \"naïve\", dans la mesure où nous nous sommes seulement contentés de remplacer les NaN par la moyenne des valeurs existantes (pour les variables quantitatives). Le traitement des données est indispensable afin que le modèle d'apprentissage accepte le format des données en entrée.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data[target]\n",
    "X = data.drop(target,axis=1)\n",
    "X0_train,X0_test,y0_train,y0_test = train_test_split(X,\\\n",
    "                                                y,\\\n",
    "                                                train_size=26000,\\\n",
    "                                                random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check target distribution between train and test just for good measure\n",
    "#add data type column info in order to identify origin, i.e. train or test\n",
    "temp = pd.DataFrame()\n",
    "temp[target[0]] = y0_train.values.astype(float).flatten().tolist() + y0_test.values.astype(float).flatten().tolist()\n",
    "temp['type_data']=['train'] * len(y0_train) + ['test']*len(y0_test) #because of simple concat\n",
    "\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(8,8),dpi=100)\n",
    "    facet = sns.FacetGrid(temp, hue=\"type_data\",aspect=5.5) #palette=\"Blues_d\"\n",
    "    facet.map(sns.kdeplot,target[0],shade= True)\n",
    "    plt.title('Distributions de %s' %(\"nb_jours_semaine\"))\n",
    "    facet.add_legend()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write train test on file\n",
    "pd.concat([X0_train,X0_test],axis=1).to_csv(\"../data/train_v0.csv\",encoding=\"utf8\")\n",
    "pd.concat([y0_train,y0_test],axis=1).to_csv(\"../data/test_v0.csv\",encoding=\"utf8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_train = X0_train.drop([\"N_ordre\"],axis=1)\n",
    "X0_test = X0_test.drop([\"N_ordre\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# II. Machine learning  <a name=\"ML\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the juicy part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Avant d'entrer dans le coeur du machine learning, il est nécessaire de définir une métrique d'évaluation.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# RMSE :root-mean-square error\n",
    "def RMSE(y_true, y_pred): \n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "def mape_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Mean Absolute  Error\n",
    "def mae_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nous allons scinder la base de train afin de pouvoir évaluer le modèle, par l'intermédiaire de la méthode de validation croisée.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import grid_search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## A. Méthode Linéaire  <a name=\"linéaire\"></a>\n",
    "    - Approche la plus naïve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Apprentissage:\n",
    "lr = LinearRegression()\n",
    "lr.fit(X0_train, y0_train)\n",
    "\n",
    "#Prédiction:\n",
    "y_lr = lr.predict(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation du modèle :\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_lr))\n",
    "print(\"La moyenne absolue d'erreur est de %s.\") %(mae_error(y0_test.values, y_lr))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## A. Méthode Linéaire  <a name=\"linéaire\"></a>\n",
    "    - Approche polynomiale et cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#poly = PolynomialFeatures(2)\n",
    "def k_fold_cross_val_poly(folds, degrees, X, y):\n",
    "    #fonction qui calcule les scores RMSE pour K-fold et d degré polynomial\n",
    "    n = len(X)\n",
    "    kf = KFold(n, n_folds=folds,random_state=42)\n",
    "    poly = PolynomialFeatures(2)\n",
    "    X_ = poly.fit_transform(X[keep])\n",
    "    X_ = pd.DataFrame(X_)\n",
    "    X = pd.concat([X_,X[keep_]],axis=1)\n",
    "    #creation du dico qui retient les scores RMSE\n",
    "    kf_dict = dict([(\"fold_%s\" % i,[]) for i in range(1, folds+1)])\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        #print \"Fold: %s\" % fold\n",
    "        X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
    "        y_train, y_test = y.ix[train_index], y.ix[test_index]\n",
    "        # Incrémente le dégré polynomial\n",
    "        for d in range(1, degrees+1):\n",
    "            #print \"Degree: %s\" % d\n",
    "            # Model & fit\n",
    "            polynomial_features = PolynomialFeatures(\n",
    "                degree=d, include_bias=False\n",
    "            )\n",
    "            linear_regression = LinearRegression()\n",
    "            model = Pipeline([\n",
    "                (\"linear_regression\", linear_regression)\n",
    "            ])\n",
    "            model.fit(X_train, y_train)\n",
    "            # Calcul du RMSE\n",
    "            y_pred = model.predict(X_test)\n",
    "            test_rmse = RMSE(y_test, y_pred)\n",
    "            #print test_rmse\n",
    "            kf_dict[\"fold_%s\" % fold].append(test_rmse) #stockage dans le dict\n",
    "        # Transform en np.array pour le moyenner\n",
    "        kf_dict[\"fold_%s\" % fold] = np.array(kf_dict[\"fold_%s\" % fold])\n",
    "    #Dans le dico\n",
    "    kf_dict[\"avg\"] = np.zeros(degrees)\n",
    "    for i in range(1, folds+1):\n",
    "        kf_dict[\"avg\"] += kf_dict[\"fold_%s\" % i]\n",
    "    kf_dict[\"avg\"] /= float(folds)\n",
    "    return kf_dict\n",
    "\n",
    "def plot_test_error_curves_kf(kf_dict, folds, degrees):\n",
    "    #fonction qui permet de visualiser les résultats calculés par la fonction ci-dessus\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ds = range(1, degrees+1)\n",
    "    for i in range(1, folds+1):\n",
    "        ax.plot(ds, kf_dict[\"fold_%s\" % i], lw=2, label='Test RMSE - Fold %s' % i)\n",
    "    ax.plot(ds, kf_dict[\"avg\"], linestyle='--', color=\"black\", lw=3, label='Avg Test RMSE')\n",
    "    ax.legend(loc=0)\n",
    "    ax.set_xlabel('Degree of Polynomial Fit')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    #ax.set_ylim([0.0, 4.0])\n",
    "    fig.set_facecolor('white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def k_fold_cross_val_poly(folds, degrees, X, y):\n",
    "    #fonction qui calcule les scores RMSE pour K-fold et d degré polynomial\n",
    "    n = len(X)\n",
    "    kf = KFold(n, n_folds=folds,random_state=42)\n",
    "    #creation du dico qui retient les scores RMSE\n",
    "    kf_dict = dict([(\"fold_%s\" % i,[]) for i in range(1, folds+1)])\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        #print \"Fold: %s\" % fold\n",
    "        X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
    "        y_train, y_test = y.ix[train_index], y.ix[test_index]\n",
    "        # Incrémente le dégré polynomial\n",
    "        for d in range(1, degrees+1):\n",
    "            #print \"Degree: %s\" % d\n",
    "            # Model & fit\n",
    "            polynomial_features = PolynomialFeatures(\n",
    "                degree=d, include_bias=False\n",
    "            )\n",
    "            linear_regression = LinearRegression()\n",
    "            model = Pipeline([\n",
    "                (\"polynomial_features\", polynomial_features),\n",
    "                (\"linear_regression\", linear_regression)\n",
    "            ])\n",
    "            model.fit(X_train, y_train)\n",
    "            # Calcul du RMSE\n",
    "            y_pred = model.predict(X_test)\n",
    "            test_rmse = RMSE(y_test, y_pred)\n",
    "            #print test_rmse\n",
    "            kf_dict[\"fold_%s\" % fold].append(test_rmse) #stockage dans le dict\n",
    "        # Transform en np.array pour le moyenner\n",
    "        kf_dict[\"fold_%s\" % fold] = np.array(kf_dict[\"fold_%s\" % fold])\n",
    "    #Dans le dico\n",
    "    kf_dict[\"avg\"] = np.zeros(degrees)\n",
    "    for i in range(1, folds+1):\n",
    "        kf_dict[\"avg\"] += kf_dict[\"fold_%s\" % i]\n",
    "    kf_dict[\"avg\"] /= float(folds)\n",
    "    return kf_dict\n",
    "\n",
    "def plot_test_error_curves_kf(kf_dict, folds, degrees):\n",
    "    #fonction qui permet de visualiser les résultats calculés par la fonction ci-dessus\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ds = range(1, degrees+1)\n",
    "    for i in range(1, folds+1):\n",
    "        ax.plot(ds, kf_dict[\"fold_%s\" % i], lw=2, label='Test RMSE - Fold %s' % i)\n",
    "    ax.plot(ds, kf_dict[\"avg\"], linestyle='--', color=\"black\", lw=3, label='Avg Test RMSE')\n",
    "    ax.legend(loc=0)\n",
    "    ax.set_xlabel('Degree of Polynomial Fit')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    #ax.set_ylim([0.0, 4.0])\n",
    "    fig.set_facecolor('white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot la courbe d'erreur k-fold CV set\n",
    "folds = 5\n",
    "degrees = 3\n",
    "kf_dict = k_fold_cross_val_poly(folds, degrees, X, y)\n",
    "plot_test_error_curves_kf(kf_dict, folds, degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Le régresseur polynomial atteint une valeur moyenne minimale RMSE : %s pour un degré %s'\n",
    "      %(kf_dict['avg'].min(),kf_dict['avg'].argmin()+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > *** Intreprétation: on décide de choisir un degré polynomial de 2. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sélection du model:\n",
    "\n",
    "lr = LinearRegression() #init\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_ = polynomial_features.fit_transform(X[keep])\n",
    "X_ = pd.DataFrame(X_)\n",
    "X_ = pd.concat([X_,X[keep_]],axis=1)\n",
    "\n",
    "X0_train_,X0_test_,y0_train_,y0_test_ = train_test_split(X_,\\\n",
    "                                                y,\\\n",
    "                                                train_size=26000,\\\n",
    "                                                random_state=42)\n",
    "\n",
    "# Création du pipeline\n",
    "pipe = Pipeline([\n",
    "        (\"linear_regression\", lr)])#(\"polynomial_features\", polynomial_features)\n",
    "grid = dict(linear_regression__normalize=[False,True]) #espace de paramètre de la régression\n",
    "                                                        # choix sur la normalisation\n",
    "model = GridSearchCV(pipe,param_grid=grid,cv=8)\n",
    "model.fit(X0_train_, y0_train_)\n",
    "#predict\n",
    "y_lr = model.predict(X0_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation du modèle :\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test_, y_lr))\n",
    "print(\"La moyenne absolue d'erreur est de %s.\") %(mae_error(y0_test_.values, y_lr))\n",
    "print(\"Meilleur model utilisant %s.\" % ( model.best_params_))\n",
    "print('Variance score: %.2f' % r2_score(y0_test_.values, y_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## A-bis. Méthode Linéaire Lasso  \n",
    "    - Approche polynomiale et cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-0.1,1)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    this_scores = cross_val_score(lasso, X_, y, cv=n_folds, n_jobs=1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "\n",
    "scores, scores_std = np.array(scores), np.array(scores_std)\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#alphas qui minimise la RMSE:\n",
    "alpha=alphas[rmse.argmin()]\n",
    "#fit avec cet alpha"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-4, -0.5, 30)\n",
    "\n",
    "#feature polynomial d'ordre 2\n",
    "#polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "#X0_train_ = polynomial_features.fit_transform(X0_train)\n",
    "#X0_test_ = polynomial_features.fit_transform(X0_test)\n",
    "\n",
    "#list\n",
    "rmse = list()\n",
    "MAPE = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    lasso.fit(X0_train_,y0_train)\n",
    "    y_lr=lasso.predict(X0_test_)\n",
    "    rmse.append(RMSE(y0_test, y_lr))\n",
    "    MAPE.append(mae_error(y0_test.values, y_lr))\n",
    "rmse, MAPE = np.array(rmse), np.array(MAPE)\n",
    "\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "\n",
    "plt.semilogx(alphas, rmse)\n",
    "#plt.semilogx(alphas, MAPE)\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('alpha')\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title('RMSE fonction de alpha')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Evaluation du modèle :\n",
    "print(\"L'erreur type (RMSE) est de %s\") %((rmse.min()))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(MAPE[rmse.argmin()])\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_lr))\n",
    "print(\"Meilleur model utilisant alpha = %s.\" % (alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ***Interprétation : on obtient des résultats remarquables avec la régression lasso sur donnée polynomiale d'ordre 2.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## B. Méthode par plus proche voisin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn=KNeighborsRegressor()\n",
    "\n",
    "n_neighbors=[2,3,5,7,12,15,20,30,40]\n",
    "leaf_size=[7,8,10,20]\n",
    "param_grid = dict(n_neighbors=n_neighbors, leaf_size=leaf_size)\n",
    "\n",
    "model = GridSearchCV(knn, param_grid, n_jobs=-1, cv=5,scoring='neg_mean_squared_error') #neg_mean_squared_error pour\n",
    "                                                                                        #sklearn > 0.18\n",
    "model.fit(X0_train, y0_train)\n",
    "10\n",
    "#Prédiction:\n",
    "y_knn = model.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_knn))\n",
    "print(\"La moyenne absolue d'erreur est de %s \") %(mae_error(y0_test.values, y_knn))\n",
    "print(\"Meilleur model utilisant %s.\" % ( model.best_params_))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ***Interprétations : cette méthode est à ignorer...***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## C. Méthodes non-linéaires : méthodes ensemblistes  <a name=\"ensemblistes\"></a>\n",
    "\n",
    "***Ici, nous allons faire usage de méthodes non-linéaires d'apprentissage automatique, et nous verrons quelle est la meilleure méthode en termes de performances (notamment en termes de taux d'erreur et de vitesse d'exécution).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestRegressor, GradientBoostingRegressor \n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.externals import joblib\n",
    "#from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Commençons par tester la méthode de régression des fôrets aléatoires.***  <a name=\"RF\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=300, max_depth=7, n_jobs=-1, max_features=None,criterion='mae',\n",
    "                               min_samples_split=5,random_state=42)\n",
    "rf.fit(X0_train, y0_train)\n",
    "y_rf = rf.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_rf))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_rf))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ***Interprétations : résultats vraiment décevants, on va chercher à tuner un peu le model.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GridSearch et Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(criterion='mae', max_features=None,random_state=42)\n",
    "n_estimators = [100, 150, 200,300,400]\n",
    "max_depth = [2, 4, 6, 8]\n",
    "min_samples_split=[2,4,6,8]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators, min_samples_split=min_samples_split)\n",
    "model = GridSearchCV(rf, param_grid, n_jobs=-1, cv=5,scoring='neg_mean_squared_error') #neg_mean_squared_error pour\n",
    "                                                                                        #sklearn > 0.18\n",
    "model.fit(X0_train, y0_train)\n",
    "y_rf = model.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_rf))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_rf))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Meilleur model utilisant %s.\" % ( model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ***Nous obtenons une MAPE d'environ 53 % et un RMSE de 3.4. C'est légèrement mieux, mais encore une fois cela reste horrible.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cette fois, testons toujours la méthode de régression extra-trees, mais cette fois, avec un nombre d'estimateurs plus important (porté à 300), et une profondeur maximale bien plus réduite (profondeur maximale de 7).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "et = ExtraTreesRegressor(n_estimators=300, criterion='mae',max_depth=7,n_jobs=-1,\n",
    "                         min_samples_split=5,max_features=None)\n",
    "et.fit(X0_train, y0_train)\n",
    "y_et = et.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_et))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_et))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GridSearch et Cross Validation**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "et = ExtraTreesRegressor(criterion='mse',max_features=None)\n",
    "n_estimators = [100, 150, 200,300,400]\n",
    "max_depth = [4, 6, 8,10]\n",
    "min_samples_split=[2,4,6,8]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators, min_samples_split=min_samples_split)\n",
    "model = GridSearchCV(et, param_grid, n_jobs=-1, cv=10,scoring='neg_mean_squared_error')\n",
    "model.fit(X0_train, y0_train)\n",
    "y_et = model.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_et))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Meilleur model utilisant %s.\" % ( model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pour le XG Boost: ***<a name=\"XGB\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xg = xgb.XGBRegressor(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X0_train, y0_train)\n",
    "y_xgb = xg.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_xgb))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_xgb))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xg = xgb.XGBRegressor(seed=42,nthread=-1)\n",
    "n_estimators = [100, 150, 200,300,400]\n",
    "max_depth = [2, 4, 6, 8]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "model = GridSearchCV(xg, param_grid, cv=5,scoring='neg_mean_squared_error') # n_jobs=-1,\n",
    "model.fit(X0_train, y0_train)\n",
    "y_xgb = model.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_xgb))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_xgb))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "params = model.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot results\n",
    "plt.figure(figsize = (12,12))\n",
    "scores = np.array(means).reshape(len(max_depth), len(n_estimators))\n",
    "for i, value in enumerate(max_depth):\n",
    "    plt.plot(n_estimators, scores[i], label='depth: ' + str(value))\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('neg_mean_squared_error')\n",
    "plt.title(\"Profondeur v.s. Nombre d'estimateurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xg = xgb.XGBRegressor(seed=42,nthread=-1)\n",
    "n_estimators = [100, 150, 200,300,400]\n",
    "max_depth = [2, 4, 6, 8]\n",
    "learning_rate=[0.05,0.075]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators,learning_rate=learning_rate)\n",
    "model = GridSearchCV(xg, param_grid, cv=5,scoring='neg_mean_squared_error') # n_jobs=-1,\n",
    "model.fit(X0_train, y0_train)\n",
    "y_xgb = model.predict(X0_test)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_xgb))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_xgb))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Meilleur model utilisant %s.\" % ( model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test du XGBoost avec des features polynomiales :**\n",
    "\n",
    "L'intuition voudrait que le fait de dériver des features polynomiales à partir de la donnée brute soit innéficace pour les méthodes de types ensemblistes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xg = xgb.XGBRegressor(seed=42,nthread=-1)\n",
    "\n",
    "#feature polynomial d'ordre 2\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X0_train_ = polynomial_features.fit_transform(X0_train)\n",
    "X0_test_ = polynomial_features.fit_transform(X0_test)\n",
    "\n",
    "#param\n",
    "n_estimators = [100, 150, 200,300,400]\n",
    "max_depth = [2, 4, 6, 8]\n",
    "learning_rate=[0.05,0.075]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators,learning_rate=learning_rate)\n",
    "\n",
    "#GridsearchCV\n",
    "model = GridSearchCV(xg, param_grid, cv=5,scoring='neg_mean_squared_error') # n_jobs=-1,\n",
    "model.fit(X0_train_, y0_train)\n",
    "y_xgb = model.predict(X0_test_)\n",
    "\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_xgb))\n",
    "print(\"La moyenne absolue d'erreur est de %s\") %(mae_error(y0_test.values, y_xgb))\n",
    "print(\"Meilleur model utilisant %s.\" % ( model.best_params_))\n",
    "print('Variance score: %.2f' % r2_score(y0_test.values, y_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > *** Interprétation : notre intuition s'est révélée être correcte, dériver des features polynomiales n'apportent rien au modèle ensembliste.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation de l'arbre de décision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#To store a visual representation of the trees\n",
    "import graphviz\n",
    "\n",
    "xg = xgb.XGBRegressor(max_depth=4, n_estimators=400, learning_rate=0.05).fit(X0_train, y0_train)\n",
    "\n",
    "if not os.path.exists('graph/'):\n",
    "    os.makedirs('graph/')\n",
    "a=xgb.to_graphviz(xg, num_trees=2)\n",
    "#a.engine = 'circo'\n",
    "a.format = 'png'\n",
    "a.render('graph/graph.png', view=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Evaluation des modèles retenus  <a name=\"interprétation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** On étudie les deux modèles aux plus grande performances**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - ### Modèle Linéaire simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#interprétations des coéfficients\n",
    "def pretty_print_linear(coefs, names = None, sort = False,filter_=True,threshold=0.005):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    df['coef'],df['var'] = map(list, zip(*lst))\n",
    "    if filter_:\n",
    "        df = df[abs(df['coef'])>threshold]\n",
    "        df.reset_index(inplace=True,drop=True)\n",
    "    return df\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reprise du modèle linéaire\n",
    "lr = LinearRegression() #init\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_ = polynomial_features.fit_transform(X)\n",
    "#X0_test_ = polynomial_features.fit_transform(X0_test)\n",
    "\n",
    "#grid = dict(linear_regression__normalize=[False,True]) #espace de paramètre de la régression\n",
    "                                                        # choix sur la normalisation\n",
    "#model = GridSearchCV(pipe,param_grid=grid,cv=8)\n",
    "lr.fit(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reconstruire le tableau avec le nom des variables\n",
    "target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(X.columns,p) for p in polynomial_features.powers_]]\n",
    "output_df = pd.DataFrame(X_, columns = target_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Linear model:\"\n",
    "pretty_print_linear(lr.coef_,names = list(output_df.columns),sort=True,threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance_frame = pretty_print_linear(lr.coef_,names = list(output_df.columns),sort=True,threshold=0.01)\n",
    "#importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "importance_frame[0:50].plot(kind = 'barh', x = 'var', figsize = (12,12), color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ***La lecture des coefficients est peu satisfante***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - ### Modèle linéaire Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(random_state=42)\n",
    "alphas = np.logspace(-4, -0.5, 30)\n",
    "\n",
    "rmse = list()\n",
    "MAPE = list()\n",
    "lr = list()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    lasso.fit(X0_train_,y0_train)\n",
    "    lr.append(lasso)\n",
    "    y_lr=lasso.predict(X0_test_)\n",
    "    rmse.append(RMSE(y0_test, y_lr))\n",
    "    MAPE.append(mape_error(y0_test, y_lr))\n",
    "rmse, MAPE = np.array(rmse), np.array(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alphas qui minimise la RMSE:\n",
    "alpha=alphas[rmse.argmin()]\n",
    "#Evaluation du modèle :\n",
    "best_regressor = lr[rmse.argmin()]\n",
    "\n",
    "importance_frame = pretty_print_linear(best_regressor.coef_,names = list(output_df.columns),sort=True,threshold=0.0006)\n",
    "#importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "importance_frame[0:50].plot(kind = 'barh', x = 'var', figsize = (12,12), color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ***La lecture des coefficients est bien plus satisfaisante avec la régression Lasso, les interprétations à valeurs métiers ont ici un sens.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - ### Modèle XGBoost :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Plot des features selon leur importance\n",
    "\n",
    "***Dans cette étape d'évaluation du modèle, nous allons représenter sous la forme d'un diagramme horizontal les variables qui contribuent le plus au modèle, à l'aide de la méthode XGBoost.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(X0_train,label=y0_train)\n",
    "dtest = xgb.DMatrix(X0_test)\n",
    "\n",
    "params = {'booster':'gbtree', 'eta':0.2, 'max_depth':4, 'subsample':0.8, 'n_estimators':400,\n",
    "                 'silent':1, 'objective':'reg:linear', \"seed\":42, 'nhtread':12,\n",
    "                 'eval_metric':'rmse','colsample_bytree':0.7}\n",
    "    \n",
    "xg = xgb.train(params, dtrain, 400)\n",
    "y_xg = xg.predict(dtest)\n",
    "print(\"L'erreur type (RMSE) est de %s\") %(RMSE(y0_test, y_xg))\n",
    "print(\"La moyenne absolue de pourcentage d'erreur est de %s %%\") %(mape_error(y0_test, y_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = xg.get_score()\n",
    "importance_frame = pd.DataFrame({'Importance': list(importances.values()),'Feature': list(importances.keys())})\n",
    "importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "importance_frame[0:75].plot(kind = 'barh', x = 'Feature', figsize = (12,12), color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Soumission des résultats  <a name=\"submit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='../models/Approche Naive/'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
